{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pennylane","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:09:46.900183Z","iopub.execute_input":"2024-01-16T17:09:46.900736Z","iopub.status.idle":"2024-01-16T17:10:01.989904Z","shell.execute_reply.started":"2024-01-16T17:09:46.900698Z","shell.execute_reply":"2024-01-16T17:10:01.987974Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pennylane in /opt/conda/lib/python3.10/site-packages (0.34.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.24.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.11.4)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pennylane) (3.1)\nRequirement already satisfied: rustworkx in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.13.2)\nRequirement already satisfied: autograd in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.6.2)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.10.2)\nRequirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.4.4)\nRequirement already satisfied: semantic-version>=2.7 in /opt/conda/lib/python3.10/site-packages (from pennylane) (2.10.0)\nRequirement already satisfied: autoray>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.6.7)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.2.4)\nRequirement already satisfied: pennylane-lightning>=0.34 in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.34.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pennylane) (2.31.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.5.0)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd->pennylane) (0.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (2023.11.17)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport pennylane as qml","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:01.993173Z","iopub.execute_input":"2024-01-16T17:10:01.993826Z","iopub.status.idle":"2024-01-16T17:10:02.002222Z","shell.execute_reply.started":"2024-01-16T17:10:01.993767Z","shell.execute_reply":"2024-01-16T17:10:02.000386Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# XOR dataset\nXOR_INPUT = np.array([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=np.float32)\nXOR_TARGET = np.array([[0], [1], [1], [0]], dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.005761Z","iopub.execute_input":"2024-01-16T17:10:02.006718Z","iopub.status.idle":"2024-01-16T17:10:02.019750Z","shell.execute_reply.started":"2024-01-16T17:10:02.006659Z","shell.execute_reply":"2024-01-16T17:10:02.018305Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Convert the input and target data to PyTorch tensors\nX = torch.from_numpy(XOR_INPUT).view(1, 4, 2)  # Add a batch and sequence dimension\nY = torch.from_numpy(XOR_TARGET).view(1, 4, 1)  # Make sure it has the correct shape","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.023206Z","iopub.execute_input":"2024-01-16T17:10:02.023709Z","iopub.status.idle":"2024-01-16T17:10:02.033631Z","shell.execute_reply.started":"2024-01-16T17:10:02.023661Z","shell.execute_reply":"2024-01-16T17:10:02.032385Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class QRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, n_qubits=4, n_qlayers=1, batch_first=True, return_sequences=False,\n                 return_state=False, backend=\"default.qubit\"):\n        super(QRNN, self).__init__()\n        self.n_inputs = input_size\n        self.hidden_size = hidden_size\n        self.concat_size = self.n_inputs + self.hidden_size\n        self.n_qubits = n_qubits\n        self.n_qlayers = n_qlayers\n        self.backend = backend\n\n        self.batch_first = batch_first\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n\n        self.wires = [f\"wire_{i}\" for i in range(self.n_qubits)]\n        self.dev = qml.device(self.backend, wires=self.wires)\n\n        def _circuit(inputs, weights):\n            qml.templates.AngleEmbedding(inputs, wires=self.wires)\n            qml.templates.BasicEntanglerLayers(weights, wires=self.wires)\n            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires]\n\n        self.qlayer = qml.QNode(_circuit, self.dev, interface=\"torch\")\n\n        weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n\n        self.clayer_in = torch.nn.Linear(self.concat_size, n_qubits)\n        self.VQC = qml.qnn.TorchLayer(self.qlayer, weight_shapes)\n        self.clayer_out = torch.nn.Linear(self.n_qubits, self.hidden_size)\n\n    def forward(self, x, init_states=None):\n        if self.batch_first:\n            batch_size, seq_length, features_size = x.size()\n        else:\n            seq_length, batch_size, features_size = x.size()\n\n        hidden_seq = []\n        if init_states is None:\n            h_t = torch.zeros(batch_size, self.hidden_size)  # hidden state (output)\n        else:\n            h_t = init_states[0][0]\n\n        for t in range(seq_length):\n            x_t = x[:, t, :]\n            v_t = torch.cat((h_t, x_t), dim=1)\n            y_t = self.clayer_in(v_t)\n\n            h_t = torch.tanh(self.clayer_out(self.VQC(y_t)))\n\n            hidden_seq.append(h_t.unsqueeze(0))\n\n        hidden_seq = torch.cat(hidden_seq, dim=0)\n        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n\n        return hidden_seq, (h_t,)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.035425Z","iopub.execute_input":"2024-01-16T17:10:02.035863Z","iopub.status.idle":"2024-01-16T17:10:02.055335Z","shell.execute_reply.started":"2024-01-16T17:10:02.035830Z","shell.execute_reply":"2024-01-16T17:10:02.054175Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Instantiate the QRNN model\ninput_size = 2\nhidden_size = 4\nqrnn_model = QRNN(input_size=input_size, hidden_size=hidden_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.057054Z","iopub.execute_input":"2024-01-16T17:10:02.057391Z","iopub.status.idle":"2024-01-16T17:10:02.074744Z","shell.execute_reply.started":"2024-01-16T17:10:02.057362Z","shell.execute_reply":"2024-01-16T17:10:02.073658Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(qrnn_model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.076573Z","iopub.execute_input":"2024-01-16T17:10:02.076919Z","iopub.status.idle":"2024-01-16T17:10:02.086709Z","shell.execute_reply.started":"2024-01-16T17:10:02.076883Z","shell.execute_reply":"2024-01-16T17:10:02.085870Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Training loop\nepochs = 200\nfor epoch in range(epochs):\n    # Forward pass\n    outputs, _ = qrnn_model(X)\n\n    # Compute the loss\n    loss = criterion(outputs, Y)\n\n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # Print the loss every 100 epochs\n    if epoch % 100 == 0:\n        print(f'Epoch {epoch}, Loss: {loss.item()}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:02.088464Z","iopub.execute_input":"2024-01-16T17:10:02.089081Z","iopub.status.idle":"2024-01-16T17:10:18.195117Z","shell.execute_reply.started":"2024-01-16T17:10:02.089050Z","shell.execute_reply":"2024-01-16T17:10:18.193541Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 0.8013659715652466\nEpoch 100, Loss: 0.014955466613173485\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing the QRNN on XOR data\nwith torch.no_grad():\n    test_outputs, _ = qrnn_model(X)\n    for i in range(len(XOR_INPUT)):\n        input_data = XOR_INPUT[i]\n        output = test_outputs[0, i, 0].item()\n        target = XOR_TARGET[i, 0]\n        print(f'Input: {input_data}, Output: {output}, Target: {target}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:18.196852Z","iopub.execute_input":"2024-01-16T17:10:18.197220Z","iopub.status.idle":"2024-01-16T17:10:18.274116Z","shell.execute_reply.started":"2024-01-16T17:10:18.197190Z","shell.execute_reply":"2024-01-16T17:10:18.272637Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Input: [0. 0.], Output: 0.012531504034996033, Target: 0.0\nInput: [1. 0.], Output: 0.9301008582115173, Target: 1.0\nInput: [0. 1.], Output: 0.9324067831039429, Target: 1.0\nInput: [1. 1.], Output: 0.012725306674838066, Target: 0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Multi-Tasking","metadata":{}},{"cell_type":"code","source":"# Set print options to suppress scientific notation\nnp.set_printoptions(suppress=True)\n\n# XOR, OR, AND dataset\nINPUT_DATA = np.array([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=np.float32)\nX = torch.from_numpy(INPUT_DATA).view(1, 4, 2)  # Add a batch and sequence dimension\n\n# Combined targets for XOR, OR, AND\nTARGET_XOR = np.array([[0], [1], [1], [0]], dtype=np.float32)\nTARGET_OR = np.array([[0], [1], [1], [1]], dtype=np.float32)\nTARGET_AND = np.array([[0], [0], [0], [1]], dtype=np.float32)\n\nY = torch.from_numpy(np.concatenate([TARGET_XOR, TARGET_OR, TARGET_AND], axis=1)).view(1, 4, 3)  # Three output dimensions","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:18.280029Z","iopub.execute_input":"2024-01-16T17:10:18.280674Z","iopub.status.idle":"2024-01-16T17:10:18.291851Z","shell.execute_reply.started":"2024-01-16T17:10:18.280622Z","shell.execute_reply":"2024-01-16T17:10:18.290535Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class QRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, n_qubits=4, n_qlayers=1, batch_first=True, return_sequences=False,\n                 return_state=False, backend=\"default.qubit\"):\n        super(QRNN, self).__init__()\n        self.n_inputs = input_size\n        self.hidden_size = hidden_size\n        self.concat_size = self.n_inputs + self.hidden_size\n        self.n_qubits = n_qubits\n        self.n_qlayers = n_qlayers\n        self.backend = backend\n\n        self.batch_first = batch_first\n        self.return_sequences = return_sequences\n        self.return_state = return_state\n\n        self.wires = [f\"wire_{i}\" for i in range(self.n_qubits)]\n        self.dev = qml.device(self.backend, wires=self.wires)\n\n        def _circuit(inputs, weights):\n            qml.templates.AngleEmbedding(inputs, wires=self.wires)\n            qml.templates.BasicEntanglerLayers(weights, wires=self.wires)\n            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires]\n\n        self.qlayer = qml.QNode(_circuit, self.dev, interface=\"torch\")\n\n        weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n\n        self.clayer_in = torch.nn.Linear(self.concat_size, n_qubits)\n        self.VQC = qml.qnn.TorchLayer(self.qlayer, weight_shapes)\n        self.clayer_out = torch.nn.Linear(self.n_qubits, self.hidden_size)\n        self.output_layer = torch.nn.Linear(self.hidden_size, 3)  # Three output dimensions\n\n    def forward(self, x, init_states=None):\n        if self.batch_first:\n            batch_size, seq_length, features_size = x.size()\n        else:\n            seq_length, batch_size, features_size = x.size()\n\n        hidden_seq = []\n        if init_states is None:\n            h_t = torch.zeros(batch_size, self.hidden_size)  # hidden state (output)\n        else:\n            h_t = init_states[0][0]\n\n        for t in range(seq_length):\n            x_t = x[:, t, :]\n            v_t = torch.cat((h_t, x_t), dim=1)\n            y_t = self.clayer_in(v_t)\n\n            h_t = torch.tanh(self.clayer_out(self.VQC(y_t)))\n\n            hidden_seq.append(h_t.unsqueeze(0))\n\n        hidden_seq = torch.cat(hidden_seq, dim=0)\n        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n\n        # Apply the output layer\n        outputs = self.output_layer(hidden_seq)\n\n        return outputs, (h_t,)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:10:18.293619Z","iopub.execute_input":"2024-01-16T17:10:18.293990Z","iopub.status.idle":"2024-01-16T17:10:18.313019Z","shell.execute_reply.started":"2024-01-16T17:10:18.293959Z","shell.execute_reply":"2024-01-16T17:10:18.311501Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Instantiate the QRNN model\ninput_size = 2\nhidden_size = 4\nqrnn_model = QRNN(input_size=input_size, hidden_size=hidden_size)\n\n# Define loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(qrnn_model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:18:32.018820Z","iopub.execute_input":"2024-01-16T17:18:32.019364Z","iopub.status.idle":"2024-01-16T17:18:32.030719Z","shell.execute_reply.started":"2024-01-16T17:18:32.019315Z","shell.execute_reply":"2024-01-16T17:18:32.029266Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Training loop\nepochs = 200\nfor epoch in range(epochs):\n    # Forward pass\n    outputs, _ = qrnn_model(X)\n\n    # Compute the loss\n    loss = criterion(outputs, Y)\n\n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # Print the loss every 100 epochs\n    if epoch % 100 == 0:\n        print(f'Epoch {epoch}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:18:32.389240Z","iopub.execute_input":"2024-01-16T17:18:32.390261Z","iopub.status.idle":"2024-01-16T17:18:48.487977Z","shell.execute_reply.started":"2024-01-16T17:18:32.390212Z","shell.execute_reply":"2024-01-16T17:18:48.486687Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 0.30112624168395996\nEpoch 100, Loss: 6.616481550736353e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing the QRNN on XOR, OR, AND data\nwith torch.no_grad():\n    test_outputs, _ = qrnn_model(X)\n    for i in range(len(INPUT_DATA)):\n        input_data = INPUT_DATA[i]\n        output = test_outputs[0, i, :].numpy()\n        target = Y[0, i, :].numpy()\n        print(f'Input: {input_data}, Output: {output}, Target: {target}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-16T17:18:48.490233Z","iopub.execute_input":"2024-01-16T17:18:48.490614Z","iopub.status.idle":"2024-01-16T17:18:48.563346Z","shell.execute_reply.started":"2024-01-16T17:18:48.490582Z","shell.execute_reply":"2024-01-16T17:18:48.562163Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Input: [0. 0.], Output: [-0.0000069   0.00008124  0.00002685], Target: [0. 0. 0.]\nInput: [1. 0.], Output: [ 0.99974895  1.0002161  -0.00022137], Target: [1. 1. 0.]\nInput: [0. 1.], Output: [1.0002334  0.99973917 0.00020742], Target: [1. 1. 0.]\nInput: [1. 1.], Output: [-0.000076    0.99986285  0.99988174], Target: [0. 1. 1.]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}